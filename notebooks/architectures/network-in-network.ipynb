{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8W9ac0nAGFN"
      },
      "source": [
        "<image src=\"https://raw.githubusercontent.com/ramiro999/pytorch-exploration/main/images/Banner-NiN.png\" width=100%>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KilGKoOWAwEQ"
      },
      "source": [
        "# <font color='#4C5FDA'> **Network in Network** </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fL9X1UzXI4qc"
      },
      "source": [
        "The paper **<font color=\"EB9A54\">\"Network In Network\"</font>** proposes an advanced architecture that enhances the capabilities of traditional convolutional neural networks (CNNs) by using neural micro-networks, namely multilayer perceptrons (MLPs), within each convolutional layer. This structure allows for a more abstract representation of the data in each layer, potentially improving classification performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFcMKdDCJq7R"
      },
      "source": [
        "<image src=\"https://raw.githubusercontent.com/ramiro999/pytorch-exploration/main/images/NiN-1.png\" >\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLGH6JhyKTpi"
      },
      "source": [
        "<image src=\"https://raw.githubusercontent.com/ramiro999/pytorch-exploration/main/images/NiN-2.png\" >"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2SxTPEwKmZJ"
      },
      "source": [
        "**<font color=\"EB9A54\">MLP Convolution Layer (mlpconv): </font>** This layer replaces the standard linear convolution in CNNs with a mini MLP that processes each patch of the input image. It is a combination of multiple layers fully connected with ReLU activations.\n",
        "\n",
        "**<font color=\"EB9A54\"> Global Average Pooling (GAP): </font>** instead of using fully connected layers on top of the network, the NIN uses a global average pooling layer followed by a softmax activation for classification. This reduces the total number of parameters and helps reduce overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "nKlhanBzo69p"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsnMp-qCL6xi",
        "outputId": "02c45a87-e112-42d3-8ab2-7e276ffecb19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.3.0+cu121\n"
          ]
        }
      ],
      "source": [
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "WmjUKOUXK21K"
      },
      "outputs": [],
      "source": [
        "class MLPConv(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
        "    super(MLPConv, self).__init__()\n",
        "    # The 3 layers defined\n",
        "    self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
        "    self.fc1 = nn.Conv2d(out_channels, out_channels, 1)\n",
        "    self.fc2 = nn.Conv2d(out_channels, out_channels, 1)\n",
        "\n",
        "  # The method forward of the class defined such as the data of input is processing through of the network.\n",
        "  def forward(self, x):\n",
        "    x = self.conv(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.fc1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.fc2(x)\n",
        "    x = F.relu(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "PH2ib51HMWjz"
      },
      "outputs": [],
      "source": [
        "class NIN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(NIN, self).__init__()\n",
        "    # First layer MLPConv: processes the input image\n",
        "    self.mlpconv1 = MLPConv(3, 192, kernel_size=5, padding=2)\n",
        "    # Second MLPConv layer: deeper processing of features\n",
        "    self.mlpconv2 = MLPConv(192, 160, kernel_size=5, padding=2)\n",
        "    # Deeper processing before reducing resolution.\n",
        "    self.mlpconv3 = MLPConv(160, 96, kernel_size=5, padding=2)\n",
        "    # Averaging layer to reduce spatial dimensions\n",
        "    self.pooling = nn.AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
        "    # Additional MLPConv layers after resolution reduction\n",
        "    self.mlpconv4 = MLPConv(96, 192, kernel_size=3, padding=1)\n",
        "    # 1x1 convolutions that act before combining the characteristics before the final classification.\n",
        "    self.mlpconv5 = MLPConv(192, 192, kernel_size=1)\n",
        "    self.mlpconv6 = MLPConv(192, 10, kernel_size=1)\n",
        "    # Global average clustering to aggregate spatial data.\n",
        "    self.global_avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "  def forward(self,x):\n",
        "    # Pass sequentially through the first 3 layers with grouping.\n",
        "    x = self.mlpconv1(x)\n",
        "    x = self.pooling(x)\n",
        "    x = self.mlpconv2(x)\n",
        "    x = self.pooling(x)\n",
        "    x = self.mlpconv3(x)\n",
        "    x = self.pooling(x)\n",
        "    # Additional layers without intermediate grouping.\n",
        "    x = self.mlpconv4(x)\n",
        "    x = self.mlpconv5(x)\n",
        "    x = self.mlpconv6(x)\n",
        "    # Apply global average pooling to prepare the classification.\n",
        "    x = self.global_avg_pool(x)\n",
        "    # Flatten the output for the final grading layer.\n",
        "    x = x.view(x.size(0), -1)\n",
        "    return x\n",
        "\n",
        "model = NIN()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding a sample of the architecture\n",
        "input = torch.rand([2, 3, 112, 112])\n",
        "print(input.shape)\n",
        "ouput = model(input)\n",
        "print(ouput.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Qlw4uIzllib",
        "outputId": "eb459744-bbfe-4a8f-814c-11072ad810ec"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 112, 112])\n",
            "torch.Size([2, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzlcm4KFA51g"
      },
      "source": [
        "---\n",
        "# <font color='#4C5FDA'> **Referencias** </font>\n",
        "\n",
        "Network In Network\n",
        "\n",
        "https://arxiv.org/pdf/1312.4400\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XSfIiPAopug"
      },
      "source": [
        "**Elaborado por Ramiro Santiago Avila Chacon**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}