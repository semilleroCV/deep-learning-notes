{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![deep-learning-notes](https://github.com/semilleroCV/deep-learning-notes/raw/main/assets/banner-notebook.png)](https://github.com/semilleroCV/deep-learning-notes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6al02g_-W5bP"
      },
      "source": [
        "# <font color='#4C5FDA'>**U-net from scratch** </font> <a name=\"tema1\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "7JQV9edGU2ZG"
      },
      "outputs": [],
      "source": [
        "#@title **Import required libraries**\n",
        "\n",
        "# Pytorch essentials\n",
        "import torch # 2.2.1\n",
        "import torch.nn as nn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.2.1\n"
          ]
        }
      ],
      "source": [
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEaUFb73t7Hz"
      },
      "source": [
        "## <font color='#ECA702'>**U-net architecture**</font>\n",
        "\n",
        "It consists of a contracting\n",
        "path (left side) and an expansive path (right side). The contracting path follows\n",
        "the typical architecture of a convolutional network. It consists of the repeated\n",
        "application of two 3x3 convolutions (unpadded convolutions), each followed by\n",
        "a rectified linear unit (ReLU) and a 2x2 max pooling operation with stride 2\n",
        "for downsampling. At each downsampling step we double the number of feature\n",
        "channels. Every step in the expansive path consists of an upsampling of the\n",
        "feature map followed by a 2x2 convolution (“up-convolution”) that halves the\n",
        "number of feature channels, a concatenation with the correspondingly cropped\n",
        "feature map from the contracting path, and two 3x3 convolutions, each followed by a ReLU. The cropping is necessary due to the loss of border pixels\n",
        "in every convolution. At the final layer a 1x1 convolution is used to map each\n",
        "64-component feature vector to the desired number of classes. In total the network has 23 convolutional layers.\n",
        "\n",
        "<div align=\"center\"> <image src=\"https://imgs.search.brave.com/6lbIK-xzYuzh28AextLXfu6l0sxRrVbSexgE3eSLp_Q/rs:fit:860:0:0/g:ce/aHR0cHM6Ly9tZWRp/YS5nZWVrc2Zvcmdl/ZWtzLm9yZy93cC1j/b250ZW50L3VwbG9h/ZHMvMjAyMjA2MTQx/MjEyMzEvR3JvdXAx/NC5qcGc\" width=800>  </div>\n",
        "\n",
        "Each blue\n",
        "box corresponds to a multi-channel feature map. The number of channels is denoted\n",
        "on top of the box. The x-y-size is provided at the lower left edge of the box. White\n",
        "boxes represent copied feature maps. The arrows denote the different operations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAsGolDg_6Gr"
      },
      "source": [
        "### <font color='#52F17F'>**Architecture Modules**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pg3Sp9YJ0L5z"
      },
      "outputs": [],
      "source": [
        "class DoubleConvBlock(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels):\n",
        "     super().__init__()\n",
        "     self.double_conv = nn.Sequential(\n",
        "         nn.Conv2d(in_channels, out_channels, kernel_size=3),\n",
        "         nn.ReLU(inplace=True),\n",
        "         nn.Conv2d(out_channels, out_channels, kernel_size=3),\n",
        "         nn.ReLU(inplace=True)\n",
        "     )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.double_conv(x)\n",
        "\n",
        "\n",
        "class Downscaling(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels):\n",
        "    super().__init__()\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.conv = DoubleConvBlock(in_channels, out_channels)\n",
        "\n",
        "  def forward(self, x):\n",
        "    p = self.pool(x)\n",
        "    down = self.conv(p)\n",
        "    return x, down\n",
        "\n",
        "\n",
        "class Upscaling(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels):\n",
        "    super().__init__()\n",
        "\n",
        "    # To scale up the feature maps I used transposed convolution. \n",
        "    self.up_conv = nn.ConvTranspose2d(in_channels, in_channels//2, 2, stride=2)\n",
        "    self.conv = DoubleConvBlock(in_channels, out_channels)\n",
        "\n",
        "  def center_crop(self, layer, target_size):\n",
        "    _, _, layer_height, layer_width = layer.size()\n",
        "    diff_y = (layer_height - target_size[0]) // 2\n",
        "    diff_x = (layer_width - target_size[1]) // 2\n",
        "    return layer[\n",
        "        :, :, diff_y : (diff_y + target_size[0]), diff_x : (diff_x + target_size[1])\n",
        "    ]\n",
        "\n",
        "  def forward(self, x1, x2):\n",
        "    x1 = self.up_conv(x1)\n",
        "    x2 = self.center_crop(x2, x1.shape[2:])\n",
        "    x = torch.cat([x1, x2], 1)\n",
        "    return self.conv(x)\n",
        "\n",
        "\n",
        "class OutConv(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels):\n",
        "    super().__init__()\n",
        "    self.conv = nn.Conv2d(in_channels, out_channels, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.conv(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8ZLBUIfE0N5J"
      },
      "outputs": [],
      "source": [
        "class UNet(nn.Module):\n",
        "  def __init__(self, n_channels, n_classes):\n",
        "    super().__init__()\n",
        "\n",
        "    self.n_channels = n_channels\n",
        "    self.n_classes = n_classes\n",
        "\n",
        "    # Following the Unet structure, we create the model with the blocks declared above\n",
        "    self.inc = DoubleConvBlock(n_channels, 64)\n",
        "    self.down1 = Downscaling(64, 128) \n",
        "    self.down2 = Downscaling(128, 256) \n",
        "    self.down3 = Downscaling(256, 512) \n",
        "    self.down4 = Downscaling(512, 1024)\n",
        "\n",
        "    self.up_conv1 = Upscaling(1024, 512)\n",
        "    self.up_conv2 = Upscaling(512, 256)\n",
        "    self.up_conv3 = Upscaling(256, 128)\n",
        "    self.up_conv4 = Upscaling(128, 64)\n",
        "\n",
        "    self.out = OutConv(64, n_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # We create the UNet forward, don't forget the residual connections\n",
        "\n",
        "    # 3x572x572 to 64x568x568\n",
        "    inc = self.inc(x)\n",
        "\n",
        "    # 64x568x568 to 128x280x280\n",
        "    crop1, down1 = self.down1(inc)\n",
        "\n",
        "    # 6128x280x280 to 256x136x136\n",
        "    crop2, down2 = self.down2(down1)\n",
        "\n",
        "    # 256x136x136 to 512x64x64\n",
        "    crop3, down3 = self.down3(down2)\n",
        "\n",
        "    # 512x64x64 to 1024x28x28\n",
        "    crop4, down4 = self.down4(down3)\n",
        "\n",
        "    # 1024x28x28 to 512x52x52\n",
        "    upsampling1 = self.up_conv1(down4, crop4)\n",
        "\n",
        "    # 512x52x52 to 256x100x100\n",
        "    upsampling2 = self.up_conv2(upsampling1, crop3)\n",
        "\n",
        "    # 256x100x100 to 128x196x196\n",
        "    upsampling3 = self.up_conv3(upsampling2, crop2)\n",
        "\n",
        "    # 128x196x196 to 64x388x388\n",
        "    upsampling4 = self.up_conv4(upsampling3, crop1)\n",
        "\n",
        "    # 64x388x388 to 1x388x388\n",
        "    ouput = self.out(upsampling4)\n",
        "    return ouput"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6AmA5YeU2Za",
        "outputId": "a94e1225-769a-45c5-8388-9cfb6116bc1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: torch.Size([2, 1, 572, 572])\n",
            "Ouput: torch.Size([2, 1, 388, 388])\n"
          ]
        }
      ],
      "source": [
        "# Test the model to see if it returns the expected output.\n",
        "\n",
        "input_image = torch.rand([2, 1, 572, 572])\n",
        "print(f\"Input: {input_image.size()}\")\n",
        "model = UNet(n_channels=1, n_classes=1)\n",
        "ouput = model(input_image)\n",
        "print(f\"Ouput: {ouput.size()}\") # Expected: [2, 1, 388, 388]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet(\n",
            "  (inc): DoubleConvBlock(\n",
            "    (double_conv): Sequential(\n",
            "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "      (1): ReLU(inplace=True)\n",
            "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "      (3): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (down1): Downscaling(\n",
            "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (conv): DoubleConvBlock(\n",
            "      (double_conv): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (3): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (down2): Downscaling(\n",
            "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (conv): DoubleConvBlock(\n",
            "      (double_conv): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (3): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (down3): Downscaling(\n",
            "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (conv): DoubleConvBlock(\n",
            "      (double_conv): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (3): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (down4): Downscaling(\n",
            "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (conv): DoubleConvBlock(\n",
            "      (double_conv): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (3): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (up_conv1): Upscaling(\n",
            "    (up_conv): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
            "    (conv): DoubleConvBlock(\n",
            "      (double_conv): Sequential(\n",
            "        (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (3): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (up_conv2): Upscaling(\n",
            "    (up_conv): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "    (conv): DoubleConvBlock(\n",
            "      (double_conv): Sequential(\n",
            "        (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (3): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (up_conv3): Upscaling(\n",
            "    (up_conv): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
            "    (conv): DoubleConvBlock(\n",
            "      (double_conv): Sequential(\n",
            "        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (3): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (up_conv4): Upscaling(\n",
            "    (up_conv): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
            "    (conv): DoubleConvBlock(\n",
            "      (double_conv): Sequential(\n",
            "        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (3): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (out): OutConv(\n",
            "    (conv): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
