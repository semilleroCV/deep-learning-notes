{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![deep-learning-notes](https://github.com/semilleroCV/deep-learning-notes/raw/main/assets/banner-notebook.png)](https://github.com/semilleroCV/deep-learning-notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** List bellow is just a placeholder. Feel free to add, remove and swap points, if you need.\n",
    "\n",
    "- Setup: Install necessary dependencies or clone required repositories.\n",
    "- Documentation: Provide clear explanations of code, methodology, and results to facilitate understanding for future users.\n",
    "- References: Acknowledge sources of code, papers, data, and techniques used in the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **DenseNet from scratch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchinfo in c:\\users\\henry mantilla\\documents\\deep-learning-notes\\venv\\lib\\site-packages (1.8.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 24.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#@title **Install required packages**\n",
    "! pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title **Importing libraries**\n",
    "\n",
    "import torch # 2.3.1+cu121\n",
    "import torchinfo # 1.8.0\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 2.3.1+cu121\n",
      "torchinfo version: 1.8.0\n"
     ]
    }
   ],
   "source": [
    "# Note: Not all dependencies have the __version__ method.\n",
    "\n",
    "print(f\"torch version: {torch.__version__}\")\n",
    "print(f\"torchinfo version: {torchinfo.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DenseNet (Dense Convolutional Network)** : (brief explanation soon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DenseNet architecture code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseLayer(nn.Module):\n",
    "  def __init__(self, in_channels: int, growth_rate: int):\n",
    "    super(DenseLayer, self).__init__()\n",
    "\n",
    "    self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "    self.conv1 = nn.Conv2d(in_channels, 4 * growth_rate, kernel_size=1, bias=False)\n",
    "\n",
    "    self.bn2 = nn.BatchNorm2d(4*growth_rate)\n",
    "    self.conv2 = nn.Conv2d(4*growth_rate, growth_rate, kernel_size=3, padding=1, bias=False)\n",
    "\n",
    "    self.relu = nn.ReLU()\n",
    "\n",
    "  def forward(self, x: Tensor):\n",
    "    x_in = x\n",
    "\n",
    "    x = self.bn1(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.conv1(x)\n",
    "\n",
    "    x = self.bn2(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.conv2(x)\n",
    "\n",
    "    return torch.cat([x_in,x], dim=1)\n",
    "\n",
    "\n",
    "class TransitionLayer(nn.Module):\n",
    "  def __init__(self, in_channels: int, out_channels: int):\n",
    "    super(TransitionLayer, self).__init__()\n",
    "\n",
    "    self.bn = nn.BatchNorm2d(in_channels)\n",
    "    self.relu = nn.ReLU()\n",
    "    self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "    self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "  def forward(self, x: Tensor):\n",
    "    x = self.bn(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.conv(x)\n",
    "    x = self.pool(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "class DenseBlock(nn.Module):\n",
    "  def __init__(self, in_channels: int, num_layers: int, growth_rate: int):\n",
    "    super(DenseBlock, self).__init__()\n",
    "\n",
    "    self.block = nn.Sequential(*[DenseLayer(in_channels+idx*growth_rate, growth_rate) for idx in range(num_layers)])\n",
    "\n",
    "  def forward(self, x: Tensor):\n",
    "    return self.block(x)\n",
    "\n",
    "\n",
    "class ClassificationHead(nn.Module):\n",
    "  def __init__(self, in_channels: int, num_classes: int):\n",
    "    super(ClassificationHead, self).__init__()\n",
    "\n",
    "    self.pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "    self.fc = nn.Linear(in_channels, num_classes)\n",
    "\n",
    "  def forward(self, x: Tensor):\n",
    "\n",
    "    x = self.pool(x)\n",
    "    x = torch.flatten(x, start_dim=1)\n",
    "    x = self.fc(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "class DenseNet(nn.Module):\n",
    "  def __init__(self, layers_per_block: list, in_channels: int, init_output_channels: int, growth_rate: int, num_classes: int):\n",
    "    super(DenseNet, self).__init__()\n",
    "\n",
    "    self.conv_pool = nn.Sequential(\n",
    "        nn.Conv2d(in_channels, init_output_channels, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "        nn.BatchNorm2d(init_output_channels),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "    )\n",
    "\n",
    "    self.blocks = nn.ModuleList([])\n",
    "\n",
    "    blocks_in_channels = init_output_channels\n",
    "    for i, n_layers in enumerate(layers_per_block):\n",
    "        dense_block = DenseBlock(blocks_in_channels, n_layers, growth_rate)\n",
    "        self.blocks.append(dense_block)\n",
    "        blocks_in_channels += growth_rate * n_layers\n",
    "\n",
    "        if i != len(layers_per_block) - 1:\n",
    "            transition_layer = TransitionLayer(blocks_in_channels, blocks_in_channels // 2)\n",
    "            self.blocks.append(transition_layer)\n",
    "            blocks_in_channels = blocks_in_channels // 2\n",
    "\n",
    "    self.bn = nn.BatchNorm2d(blocks_in_channels)\n",
    "    self.classifier = ClassificationHead(blocks_in_channels, num_classes)\n",
    "\n",
    "  def forward(self, x: Tensor):\n",
    "    x = self.conv_pool(x)\n",
    "    x = nn.ReLU()(x)\n",
    "    for block in self.blocks:\n",
    "      x = block(x)\n",
    "\n",
    "    x = self.classifier(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "DenseNet                                      [1, 1000]                 2,048\n",
       "├─Sequential: 1-1                             [1, 64, 56, 56]           --\n",
       "│    └─Conv2d: 2-1                            [1, 64, 112, 112]         9,408\n",
       "│    └─BatchNorm2d: 2-2                       [1, 64, 112, 112]         128\n",
       "│    └─ReLU: 2-3                              [1, 64, 112, 112]         --\n",
       "│    └─MaxPool2d: 2-4                         [1, 64, 56, 56]           --\n",
       "├─ModuleList: 1-2                             --                        --\n",
       "│    └─DenseBlock: 2-5                        [1, 256, 56, 56]          --\n",
       "│    │    └─Sequential: 3-1                   [1, 256, 56, 56]          335,040\n",
       "│    └─TransitionLayer: 2-6                   [1, 128, 28, 28]          --\n",
       "│    │    └─BatchNorm2d: 3-2                  [1, 256, 56, 56]          512\n",
       "│    │    └─ReLU: 3-3                         [1, 256, 56, 56]          --\n",
       "│    │    └─Conv2d: 3-4                       [1, 128, 56, 56]          32,768\n",
       "│    │    └─AvgPool2d: 3-5                    [1, 128, 28, 28]          --\n",
       "│    └─DenseBlock: 2-7                        [1, 512, 28, 28]          --\n",
       "│    │    └─Sequential: 3-6                   [1, 512, 28, 28]          919,680\n",
       "│    └─TransitionLayer: 2-8                   [1, 256, 14, 14]          --\n",
       "│    │    └─BatchNorm2d: 3-7                  [1, 512, 28, 28]          1,024\n",
       "│    │    └─ReLU: 3-8                         [1, 512, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-9                       [1, 256, 28, 28]          131,072\n",
       "│    │    └─AvgPool2d: 3-10                   [1, 256, 14, 14]          --\n",
       "│    └─DenseBlock: 2-9                        [1, 1024, 14, 14]         --\n",
       "│    │    └─Sequential: 3-11                  [1, 1024, 14, 14]         2,837,760\n",
       "│    └─TransitionLayer: 2-10                  [1, 512, 7, 7]            --\n",
       "│    │    └─BatchNorm2d: 3-12                 [1, 1024, 14, 14]         2,048\n",
       "│    │    └─ReLU: 3-13                        [1, 1024, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-14                      [1, 512, 14, 14]          524,288\n",
       "│    │    └─AvgPool2d: 3-15                   [1, 512, 7, 7]            --\n",
       "│    └─DenseBlock: 2-11                       [1, 1024, 7, 7]           --\n",
       "│    │    └─Sequential: 3-16                  [1, 1024, 7, 7]           2,158,080\n",
       "├─ClassificationHead: 1-3                     [1, 1000]                 --\n",
       "│    └─AdaptiveAvgPool2d: 2-12                [1, 1024, 1, 1]           --\n",
       "│    └─Linear: 2-13                           [1, 1000]                 1,025,000\n",
       "===============================================================================================\n",
       "Total params: 7,978,856\n",
       "Trainable params: 7,978,856\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 2.83\n",
       "===============================================================================================\n",
       "Input size (MB): 0.60\n",
       "Forward/backward pass size (MB): 180.14\n",
       "Params size (MB): 31.91\n",
       "Estimated Total Size (MB): 212.65\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "densenet_config = {\n",
    "    'densenet-121': [6,12,24,16],\n",
    "    'densenet-169': [6,12,32,32],\n",
    "    'densenet-201': [6,12,48,32],\n",
    "    'densenet-264': [6,12,64,48]\n",
    "}\n",
    "\n",
    "model = DenseNet(layers_per_block=densenet_config['densenet-121'], in_channels=3, init_output_channels=64, growth_rate=32, num_classes=1000)\n",
    "torchinfo.summary(model, (3, 224, 224), batch_dim = 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
