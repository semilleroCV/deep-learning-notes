{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![deep-learning-notes](https://github.com/semilleroCV/deep-learning-notes/raw/main/assets/banner-notebook.png)](https://github.com/semilleroCV/deep-learning-notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Mixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "#@title **Install required packages**\n",
    "\n",
    "! pip install torchinfo einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Henry Mantilla\\Documents\\deep-learning-notes\\venv\\Lib\\site-packages\\torch\\cuda\\__init__.py:749: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ..\\c10\\cuda\\CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() if nvml_count < 0 else nvml_count\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.0 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"c:\\Users\\Henry Mantilla\\Documents\\deep-learning-notes\\venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\Henry Mantilla\\Documents\\deep-learning-notes\\venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\Henry Mantilla\\Documents\\deep-learning-notes\\venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\Henry Mantilla\\Documents\\deep-learning-notes\\venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Python311\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Python311\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Python311\\Lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\Henry Mantilla\\Documents\\deep-learning-notes\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\Henry Mantilla\\Documents\\deep-learning-notes\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\Henry Mantilla\\Documents\\deep-learning-notes\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\Henry Mantilla\\Documents\\deep-learning-notes\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"c:\\Users\\Henry Mantilla\\Documents\\deep-learning-notes\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\Henry Mantilla\\Documents\\deep-learning-notes\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\Henry Mantilla\\Documents\\deep-learning-notes\\venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\Henry Mantilla\\Documents\\deep-learning-notes\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\Henry Mantilla\\Documents\\deep-learning-notes\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\Henry Mantilla\\Documents\\deep-learning-notes\\venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\Henry Mantilla\\Documents\\deep-learning-notes\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\Henry Mantilla\\Documents\\deep-learning-notes\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\Henry Mantilla\\Documents\\deep-learning-notes\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Edson\\AppData\\Local\\Temp\\ipykernel_20824\\544628795.py\", line 8, in <module>\n",
      "    from einops.layers.torch import Rearrange\n",
      "  File \"c:\\Users\\Henry Mantilla\\Documents\\deep-learning-notes\\venv\\Lib\\site-packages\\einops\\layers\\torch.py\", line 7, in <module>\n",
      "    from .._torch_specific import apply_for_scriptable_torch\n",
      "  File \"c:\\Users\\Henry Mantilla\\Documents\\deep-learning-notes\\venv\\Lib\\site-packages\\einops\\_torch_specific.py\", line 128, in <module>\n",
      "    allow_ops_in_compiled_graph()\n",
      "  File \"c:\\Users\\Henry Mantilla\\Documents\\deep-learning-notes\\venv\\Lib\\site-packages\\einops\\_torch_specific.py\", line 107, in allow_ops_in_compiled_graph\n",
      "    from torch._dynamo import allow_in_graph\n",
      "  File \"c:\\Users\\Henry Mantilla\\Documents\\deep-learning-notes\\venv\\Lib\\site-packages\\torch\\_dynamo\\__init__.py\", line 64, in <module>\n",
      "    torch.manual_seed = disable(torch.manual_seed)\n",
      "  File \"c:\\Users\\Henry Mantilla\\Documents\\deep-learning-notes\\venv\\Lib\\site-packages\\torch\\_dynamo\\decorators.py\", line 50, in disable\n",
      "    return DisableContext()(fn)\n",
      "  File \"c:\\Users\\Henry Mantilla\\Documents\\deep-learning-notes\\venv\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py\", line 410, in __call__\n",
      "    (filename is None or trace_rules.check(fn))\n",
      "  File \"c:\\Users\\Henry Mantilla\\Documents\\deep-learning-notes\\venv\\Lib\\site-packages\\torch\\_dynamo\\trace_rules.py\", line 3378, in check\n",
      "    return check_verbose(obj, is_inlined_call).skipped\n",
      "  File \"c:\\Users\\Henry Mantilla\\Documents\\deep-learning-notes\\venv\\Lib\\site-packages\\torch\\_dynamo\\trace_rules.py\", line 3361, in check_verbose\n",
      "    rule = torch._dynamo.trace_rules.lookup_inner(\n",
      "  File \"c:\\Users\\Henry Mantilla\\Documents\\deep-learning-notes\\venv\\Lib\\site-packages\\torch\\_dynamo\\trace_rules.py\", line 3442, in lookup_inner\n",
      "    rule = get_torch_obj_rule_map().get(obj, None)\n",
      "  File \"c:\\Users\\Henry Mantilla\\Documents\\deep-learning-notes\\venv\\Lib\\site-packages\\torch\\_dynamo\\trace_rules.py\", line 2782, in get_torch_obj_rule_map\n",
      "    obj = load_object(k)\n",
      "  File \"c:\\Users\\Henry Mantilla\\Documents\\deep-learning-notes\\venv\\Lib\\site-packages\\torch\\_dynamo\\trace_rules.py\", line 2811, in load_object\n",
      "    val = _load_obj_from_str(x[0])\n",
      "  File \"c:\\Users\\Henry Mantilla\\Documents\\deep-learning-notes\\venv\\Lib\\site-packages\\torch\\_dynamo\\trace_rules.py\", line 2795, in _load_obj_from_str\n",
      "    return getattr(importlib.import_module(module), obj_name)\n",
      "  File \"C:\\Python311\\Lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"c:\\Users\\Henry Mantilla\\Documents\\deep-learning-notes\\venv\\Lib\\site-packages\\torch\\nested\\_internal\\nested_tensor.py\", line 417, in <module>\n",
      "    values=torch.randn(3, 3, device=\"meta\"),\n",
      "c:\\Users\\Henry Mantilla\\Documents\\deep-learning-notes\\venv\\Lib\\site-packages\\torch\\nested\\_internal\\nested_tensor.py:417: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  values=torch.randn(3, 3, device=\"meta\"),\n"
     ]
    }
   ],
   "source": [
    "#@title **Importing libraries**\n",
    "\n",
    "import torch #2.3.1+cu121\n",
    "import torch.nn as nn \n",
    "import torchinfo #1.8.0\n",
    "\n",
    "import einops #0.8.0\n",
    "from einops.layers.torch import Rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 2.3.1+cu121\n",
      "torchinfo version: 1.8.0\n",
      "einops version: 0.8.0\n"
     ]
    }
   ],
   "source": [
    "# Note: Not all dependencies have the __version__ method.\n",
    "\n",
    "print(f\"torch version: {torch.__version__}\")\n",
    "print(f\"torchinfo version: {torchinfo.__version__}\")\n",
    "print(f\"einops version: {einops.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP-Mixer architecture code\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEmbedding(nn.Module):\n",
    "    def __init__(self, in_channels: int, patch_size: int, embed_dim: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.proj = nn.Conv2d(in_channels, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "        self.rearrange = Rearrange('b e h w -> b (h w) e')\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, _, H, W = x.size()\n",
    "\n",
    "        x = self.proj(x)\n",
    "        x = self.rearrange(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class MLPBlock(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dim: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.mlp_blk = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hidden_dim, input_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "      return self.mlp_blk(x)\n",
    "\n",
    "\n",
    "class MixerBlock(nn.Module):\n",
    "    def __init__(self, dim: int, pix_per_patch: int, token_dim: int, channel_dim: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.token_mixer = nn.Sequential(\n",
    "            nn.LayerNorm(dim),\n",
    "            Rearrange('b n c -> b c n'),\n",
    "            MLPBlock(pix_per_patch, token_dim),\n",
    "            Rearrange('b c n -> b n c'),\n",
    "        )\n",
    "\n",
    "        self.channel_mixer = nn.Sequential(\n",
    "            nn.LayerNorm(dim),\n",
    "            MLPBlock(dim, channel_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = x + self.token_mixer(x)\n",
    "        x = x + self.channel_mixer(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class MLPMixer(nn.Module):\n",
    "    def __init__(self, num_classes: int, hidden_dim: int, depth: int, in_channels: int = 3, img_size: int = 224,\n",
    "                 patch_size: int = 16, token_dim: int = 256, channel_dim: int = 256):\n",
    "        super().__init__()\n",
    "\n",
    "        self.patch_embed = PatchEmbedding(in_channels, patch_size, hidden_dim)\n",
    "        pix_per_patch =  (img_size// patch_size) ** 2\n",
    "\n",
    "        self.mixer_blks = nn.Sequential()\n",
    "\n",
    "        for i in range(depth):\n",
    "            self.mixer_blks.add_module(f\"MixerBlock_{i}\", \n",
    "                                       MixerBlock(hidden_dim, pix_per_patch, token_dim, channel_dim))\n",
    "\n",
    "        self.norm = nn.LayerNorm(hidden_dim)\n",
    "        self.head = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.patch_embed(x)\n",
    "        x = self.mixer_blks(x)\n",
    "        x = self.norm(x)\n",
    "        x = x.mean(dim=1)\n",
    "        x = self.head(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "MLPMixer                                      [1, 1000]                 --\n",
       "├─PatchEmbedding: 1-1                         [1, 196, 512]             --\n",
       "│    └─Conv2d: 2-1                            [1, 512, 14, 14]          393,728\n",
       "│    └─Rearrange: 2-2                         [1, 196, 512]             --\n",
       "├─Sequential: 1-2                             [1, 196, 512]             --\n",
       "│    └─MixerBlock: 2-3                        [1, 196, 512]             --\n",
       "│    │    └─Sequential: 3-1                   [1, 196, 512]             101,828\n",
       "│    │    └─Sequential: 3-2                   [1, 196, 512]             2,100,736\n",
       "│    └─MixerBlock: 2-4                        [1, 196, 512]             --\n",
       "│    │    └─Sequential: 3-3                   [1, 196, 512]             101,828\n",
       "│    │    └─Sequential: 3-4                   [1, 196, 512]             2,100,736\n",
       "│    └─MixerBlock: 2-5                        [1, 196, 512]             --\n",
       "│    │    └─Sequential: 3-5                   [1, 196, 512]             101,828\n",
       "│    │    └─Sequential: 3-6                   [1, 196, 512]             2,100,736\n",
       "│    └─MixerBlock: 2-6                        [1, 196, 512]             --\n",
       "│    │    └─Sequential: 3-7                   [1, 196, 512]             101,828\n",
       "│    │    └─Sequential: 3-8                   [1, 196, 512]             2,100,736\n",
       "│    └─MixerBlock: 2-7                        [1, 196, 512]             --\n",
       "│    │    └─Sequential: 3-9                   [1, 196, 512]             101,828\n",
       "│    │    └─Sequential: 3-10                  [1, 196, 512]             2,100,736\n",
       "│    └─MixerBlock: 2-8                        [1, 196, 512]             --\n",
       "│    │    └─Sequential: 3-11                  [1, 196, 512]             101,828\n",
       "│    │    └─Sequential: 3-12                  [1, 196, 512]             2,100,736\n",
       "│    └─MixerBlock: 2-9                        [1, 196, 512]             --\n",
       "│    │    └─Sequential: 3-13                  [1, 196, 512]             101,828\n",
       "│    │    └─Sequential: 3-14                  [1, 196, 512]             2,100,736\n",
       "│    └─MixerBlock: 2-10                       [1, 196, 512]             --\n",
       "│    │    └─Sequential: 3-15                  [1, 196, 512]             101,828\n",
       "│    │    └─Sequential: 3-16                  [1, 196, 512]             2,100,736\n",
       "├─LayerNorm: 1-3                              [1, 196, 512]             1,024\n",
       "├─Linear: 1-4                                 [1, 1000]                 513,000\n",
       "===============================================================================================\n",
       "Total params: 18,528,264\n",
       "Trainable params: 18,528,264\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 95.31\n",
       "===============================================================================================\n",
       "Input size (MB): 0.60\n",
       "Forward/backward pass size (MB): 61.38\n",
       "Params size (MB): 74.11\n",
       "Estimated Total Size (MB): 136.10\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MLPMixer(num_classes=1000, hidden_dim=512, depth=8, patch_size=16,\n",
    "                 token_dim=256, channel_dim=2048)\n",
    "torchinfo.summary(model, (3, 224, 224), batch_dim = 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
