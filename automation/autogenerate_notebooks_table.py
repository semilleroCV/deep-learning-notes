from __future__ import annotations

import argparse
from dataclasses import dataclass
from typing import Optional, List
from enum import Enum

NOTEBOOKS_ROOT_PATH = "https://github.com/semilleroCV/deep-learning-notes/blob/main/notebooks"
NOTEBOOKS_COLAB_ROOT_PATH = "github/semilleroCV/deep-learning-notes/blob/main/notebooks"

WARNING_HEADER = [
    "<!---",
    "   WARNING: DO NOT EDIT THIS TABLE MANUALLY. IT IS AUTOMATICALLY GENERATED.",
    "   HEAD OVER TO CONTRIBUTING.MD FOR MORE DETAILS ON HOW TO MAKE CHANGES PROPERLY.",
    "-->"
]

TABLE_HEADER = [
    "| **notebook** | **open in colab** | **complementary materials** | **repository / paper** |",
    "|:------------:|:-----------------:|:---------------------------:|:----------------------:|"
]

# Update section headers based on your notebook folders
SECTIONS = {
    "architectures": "## üèóÔ∏è Architectures",
    "losses": "## ‚ùå Loss Functions",
    "metrics": "## üìè Metrics",
    "modules": "## üß© Modules",
    "data_exploration": "## üîç Data Exploration"
}

NOTEBOOK_LINK_PATTERN = "[{}]({}/{})"
OPEN_IN_COLAB_BADGE_PATTERN = "[![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/{}/{})"
YOUTUBE_BADGE_PATTERN = "[![YouTube](https://badges.aleen42.com/src/youtube.svg)]({})"
GITHUB_BADGE_PATTERN = "[![GitHub](https://badges.aleen42.com/src/github.svg)]({})"
ARXIV_BADGE_PATTERN = "[![arXiv](https://img.shields.io/badge/arXiv-{}-b31b1b.svg)](https://arxiv.org/abs/{})"

AUTOGENERATED_NOTEBOOKS_TABLE_TOKEN = "<!--- AUTOGENERATED-NOTEBOOKS-TABLE -->"

@dataclass(frozen=True)
class TableEntry:
    display_name: str
    notebook_name: str
    youtube_video_path: Optional[str]
    github_repository_path: Optional[str]
    arxiv_index: Optional[str]

    @classmethod
    def from_csv_line(cls, csv_line: str) -> TableEntry:
        csv_fields = [
            field.strip()
            for field
            in csv_line.split(",")
        ]
        if len(csv_fields) != 5:
            raise Exception("Every csv line must contain 5 fields")
        return TableEntry(
            display_name=csv_fields[0],
            notebook_name=csv_fields[1],
            youtube_video_path=csv_fields[2],
            github_repository_path=csv_fields[3],
            arxiv_index=csv_fields[4]
        )

    def format(self) -> str:
        section = self.notebook_name.split('/')[0]
        notebook_link = NOTEBOOK_LINK_PATTERN.format(self.display_name, NOTEBOOKS_ROOT_PATH, self.notebook_name)
        open_in_colab_badge = OPEN_IN_COLAB_BADGE_PATTERN.format(NOTEBOOKS_COLAB_ROOT_PATH, self.notebook_name)
        youtube_badge = YOUTUBE_BADGE_PATTERN.format(self.youtube_video_path) if self.youtube_video_path else ""
        github_badge = GITHUB_BADGE_PATTERN.format(self.github_repository_path) if self.github_repository_path else ""
        arxiv_badge = ARXIV_BADGE_PATTERN.format(self.arxiv_index, self.arxiv_index) if self.arxiv_index else ""
        return section, f"| {notebook_link} | {open_in_colab_badge} | {youtube_badge} | {github_badge} {arxiv_badge}|"

def read_lines_from_file(path: str) -> List[str]:
    with open(path) as file:
        return [line.rstrip() for line in file]

def save_lines_to_file(path: str, lines: List[str]) -> None:
    with open(path, "w") as f:
        for line in lines:
            f.write("%s\n" % line)

def parse_csv_lines(csv_lines: List[str]) -> List[TableEntry]:
    return [
        TableEntry.from_csv_line(csv_line=csv_line)
        for csv_line
        in csv_lines
    ]

def search_lines_with_token(lines: List[str], token: str) -> List[int]:
    result = []
    for line_index, line in enumerate(lines):
        if token in line:
            result.append(line_index)
    return result

def inject_markdown_table_into_readme(readme_lines: List[str], table_lines: List[str]) -> List[str]:
    lines_with_token_indexes = search_lines_with_token(lines=readme_lines, token=AUTOGENERATED_NOTEBOOKS_TABLE_TOKEN)
    if len(lines_with_token_indexes) != 2:
        raise Exception(f"Please inject two {AUTOGENERATED_NOTEBOOKS_TABLE_TOKEN} "
                        f"tokens to signal start and end of autogenerated table.")

    [table_start_line_index, table_end_line_index] = lines_with_token_indexes
    return readme_lines[:table_start_line_index + 1] + table_lines + readme_lines[table_end_line_index:]

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('-d', '--data_path', default='automation/notebooks-table-data.csv')
    parser.add_argument('-r', '--readme_path', default='README.md')
    args = parser.parse_args()

    csv_lines = read_lines_from_file(path=args.data_path)[1:]
    readme_lines = read_lines_from_file(path=args.readme_path)
    table_entries = parse_csv_lines(csv_lines=csv_lines)

    section_entries = {section: [] for section in SECTIONS.keys()}
    for entry in table_entries:
        section, formatted_entry = entry.format()
        if section in section_entries:
            section_entries[section].append(formatted_entry)
    
    table_lines = WARNING_HEADER
    for section, header in SECTIONS.items():
        section_lines = section_entries.get(section, [])
        if section_lines:
            table_lines += [header + f" ({len(section_lines)} notebooks)"] + TABLE_HEADER + section_lines

    readme_lines = inject_markdown_table_into_readme(readme_lines=readme_lines, table_lines=table_lines)
    save_lines_to_file(path=args.readme_path, lines=readme_lines)
